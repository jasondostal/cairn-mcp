# Cairn: Semantic Memory for AI Agents
# Copy to .env and fill in values

# PostgreSQL
CAIRN_DB_HOST=cairn-db
CAIRN_DB_PORT=5432
CAIRN_DB_NAME=cairn
CAIRN_DB_USER=cairn
CAIRN_DB_PASS=cairn-dev-password

# LLM Backend: "ollama" (default, local) or "bedrock" (AWS)
CAIRN_LLM_BACKEND=ollama

# AWS Bedrock (when CAIRN_LLM_BACKEND=bedrock)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1
CAIRN_BEDROCK_MODEL=us.meta.llama3-2-90b-instruct-v1:0

# Ollama (when CAIRN_LLM_BACKEND=ollama)
CAIRN_OLLAMA_URL=http://host.docker.internal:11434
CAIRN_OLLAMA_MODEL=qwen2.5-coder:7b

# Transport: "stdio" (docker exec) or "http" (network)
CAIRN_TRANSPORT=http
CAIRN_HTTP_HOST=0.0.0.0
CAIRN_HTTP_PORT=8000

# Enrichment: set to "false" to disable LLM enrichment on store
CAIRN_ENRICHMENT_ENABLED=true

# LLM Capabilities (v0.6.0): each can be toggled independently
CAIRN_LLM_QUERY_EXPANSION=true
CAIRN_LLM_RELATIONSHIP_EXTRACT=true
CAIRN_LLM_RULE_CONFLICT_CHECK=true
CAIRN_LLM_SESSION_SYNTHESIS=true
CAIRN_LLM_CONSOLIDATION=true
CAIRN_LLM_CONFIDENCE_GATING=false

# Embedding (always local)
CAIRN_EMBEDDING_MODEL=all-MiniLM-L6-v2
